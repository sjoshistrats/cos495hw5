{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COS 495 PSET 5: ConvNets at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running locally, you'll have to install TensorFlow via `Pkg.checkout(\"TensorFlow\")`\n",
    "You'll also have to install Plots and Images via `Pkg.add`.\n",
    "And install MLDatasets via Pkg.clone(\"https://github.com/JuliaML/MLDatasets.jl.git\")\n",
    "All these packages come pre-installed on the AMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using TensorFlow, MLDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x, train_y = CIFAR10.traindata()\n",
    "train_y .+= 1      # transform 0..9 to 1..10\n",
    "categories = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "type DataLoader\n",
    "    cur_id::Int\n",
    "    order::Vector{Int}\n",
    "end\n",
    "\n",
    "loader_train = DataLoader(1, shuffle(1:45000))\n",
    "loader_val = DataLoader(1, shuffle(45001:50000))    # use last 5000 examples for validation set\n",
    "\n",
    "function next_batch(loader::DataLoader, batch_size)\n",
    "    x = zeros(Float32, batch_size, 32*32*3)\n",
    "    y = zeros(Float32, batch_size, 10)\n",
    "    for i in 1:batch_size\n",
    "        x[i, :] = train_x[:,:,:,loader.order[loader.cur_id]][:]\n",
    "        label = train_y[loader.order[loader.cur_id]]\n",
    "        y[i, Int(label)] = 1.0\n",
    "        loader.cur_id += 1\n",
    "        if loader.cur_id > length(loader.order)\n",
    "            loader.cur_id = 1\n",
    "        end\n",
    "    end\n",
    "    x, y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View some images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Plots, Images\n",
    "gr(size=(600,600))\n",
    "\n",
    "# function for displaying a stack of images\n",
    "# imgstack is mxnxp array that contains p images, each of which is mxn \n",
    "function montage(imgstack,titles)\n",
    "    plot(\n",
    "        [plot(\n",
    "                colorview(RGB,permutedims(imgstack[:,:,:,i],(3,1,2))),\n",
    "                title=titles[i],\n",
    "                aspect_ratio=:equal\n",
    "            ) for i=1:size(imgstack,4)]...,\n",
    "        legend = :none, axis = nothing     # options necessary to get nice spacing of the images\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "montage(train_x[:,:,:,1:16],categories[train_y[1:16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 2000\n",
    "batch_size = 128\n",
    "val_batch_size = 512\n",
    "display_step = 50\n",
    "\n",
    "# Network Parameters\n",
    "input_shape = [32, 32, 3] # 32x32 RGB images\n",
    "n_classes = 10 # CIFAR-10 total classes\n",
    "dropout = 1.0 # probability to keep units (1.0 indicates no dropout)\n",
    "\n",
    "# tf Graph input\n",
    "session = Session(Graph())\n",
    "\n",
    "x = placeholder(Float32)\n",
    "y = placeholder(Float32)\n",
    "keep_prob = placeholder(Float32) # dropout keep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "function conv2d(x, W, b, strides=1)\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    return nn.relu( b + nn.conv2d(x, W, [1, strides, strides, 1], \"SAME\") )\n",
    "end\n",
    "\n",
    "function maxpool2d(x, k=2)\n",
    "    # MaxPool2D wrapper\n",
    "    return nn.max_pool(x, [1, k, k, 1], [1, k, k, 1], \"SAME\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "function conv_net(x, weights, biases, dropout)\n",
    "    # Reshape input picture\n",
    "    x = reshape(x, [-1, 32, 32, 3])\n",
    "\n",
    "    conv1 = maxpool2d(conv2d(x, weights[\"wc1\"], biases[\"bc1\"]))\n",
    "    conv2 = conv2d(conv1, weights[\"wc2\"], biases[\"bc2\"])\n",
    "    conv3 = maxpool2d(conv2d(conv2, weights[\"wc3\"], biases[\"bc3\"]))\n",
    "\n",
    "    # transition to fully connected layer\n",
    "    # Reshape conv3 output to fit fully connected layer input\n",
    "    fc1 = reshape(conv3, [-1, get(get_shape(weights[\"wd1\"]).dims[1])])\n",
    "    fc1 = nn.relu( fc1 * weights[\"wd1\"] + biases[\"bd1\"] )\n",
    "    # Apply Dropout\n",
    "    fc1 = nn.dropout(fc1, dropout)\n",
    "    \n",
    "    # Output, class prediction \n",
    "    return fc1 * weights[\"out\"] + biases[\"out\"]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = Dict(\n",
    "    # 3x3 conv, 3 inputs, 32 outputs\n",
    "    \"wc1\" => Variable(0.05*randn(Float32, 3, 3, 3, 32)),\n",
    "    # 3x3 conv, 32 inputs, 64 outputs\n",
    "    \"wc2\" => Variable(0.05*randn(Float32, 3, 3, 32, 64)),\n",
    "    # 3x3 conv, 64 inputs, 64 outputs\n",
    "    \"wc3\" => Variable(0.05*randn(Float32, 3, 3, 64, 64)),\n",
    "    # fully connected, 7*7*64 inputs, 512 outputs\n",
    "    \"wd1\" => Variable(0.05*randn(Float32, 8*8*64, 512)),\n",
    "    # fully connected, 512 inputs, 512 outputs\n",
    "    \"out\" => Variable(0.05*randn(Float32, 512, n_classes))\n",
    ")\n",
    "\n",
    "biases = Dict(\n",
    "    \"bc1\" => Variable(zeros(Float32, 32)),\n",
    "    \"bc2\" => Variable(zeros(Float32, 64)),\n",
    "    \"bc3\" => Variable(zeros(Float32, 64)),\n",
    "    \"bd1\" => Variable(zeros(Float32, 512)),\n",
    "    \"out\" => Variable(zeros(Float32, n_classes))\n",
    ")\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "soft = nn.softmax(pred) \n",
    "#cost = reduce_mean(nn.softmax_cross_entropy_with_logits(pred, y))   # the right way but alas not wrapped for Julia\n",
    "cross_entropy = reduce_mean(-reduce_sum(y.*log(soft), axis=[2]))   # could cause underflow/overflow problems\n",
    "\n",
    "optimizer = train.minimize(train.AdamOptimizer(learning_rate), cross_entropy)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = indmax(pred, 2) .== indmax(y, 2)\n",
    "accuracy = reduce_mean(cast(correct_pred, Float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# launch the graph\n",
    "run(session, init)\n",
    "\n",
    "# initialize accuracy/loss arrays\n",
    "train_acc = zeros(div(training_iters,display_step))\n",
    "train_loss = zeros(div(training_iters,display_step))\n",
    "val_acc = zeros(div(training_iters,display_step))\n",
    "val_loss = zeros(div(training_iters,display_step))\n",
    "\n",
    "# keep training until reach max iterations\n",
    "for step = 1:training_iters\n",
    "    batch_x, batch_y = next_batch(loader_train, batch_size)\n",
    "    run(session, optimizer, Dict(x => batch_x, y => batch_y, keep_prob => dropout))\n",
    "    if step % display_step == 0\n",
    "        println(step)\n",
    "        ibatch = div(step,display_step)\n",
    "        train_loss[ibatch], train_acc[ibatch] =\n",
    "            run(session, [cross_entropy, accuracy], Dict(x => batch_x, y => batch_y, keep_prob => 1.))\n",
    "        val_batch_x, val_batch_y = next_batch(loader_val, val_batch_size)\n",
    "        val_loss[ibatch], val_acc[ibatch], this_soft = \n",
    "            run(session, [cross_entropy, accuracy, soft], Dict( x => val_batch_x, y=> val_batch_y, keep_prob=> 1.))\n",
    "        \n",
    "        IJulia.clear_output(true)\n",
    "        xvals = display_step:display_step:step\n",
    "        truelabel = indmax(val_batch_y[1,:])\n",
    "        plot(\n",
    "            plot(xvals,[train_acc[1:ibatch],val_acc[1:ibatch]], \n",
    "                title=\"Classification accuracy\", \n",
    "                label=[\"training\", \"validation\"],\n",
    "                xlabel=\"# minibatches\",\n",
    "                ylabel=\"Accuracy\"\n",
    "                ),\n",
    "            plot(xvals,[train_loss[1:ibatch],val_loss[1:ibatch]], \n",
    "                title=\"Cross entropy loss\",\n",
    "                label=[\"training\", \"validation\"],\n",
    "                xlabel=\"# minibatches\"\n",
    "                ),\n",
    "            plot(colorview(RGB,permutedims(reshape(val_batch_x[1,:],32,32,3),(3,1,2))),\n",
    "                title = \"Input image\",\n",
    "                xlabel = string(\"true label: \", truelabel, \" \", categories[truelabel])\n",
    "                ),\n",
    "            bar(this_soft[1,:],\n",
    "                title = \"Class probabilities\",\n",
    "                legend = :none\n",
    "            )\n",
    "        ) |> display\n",
    "        sleep(0.01)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
